{"ast":null,"code":"// import imageAEI from \"../assets/AEI.png\";\n// import imageBMP from \"../assets/BMP.png\";\n// import imageN from \"../assets/Nn.png\";\n// import imageCDGKNRSTXYZ from \"../assets/CDGKNRSTXYZ.png\";\n// import imageCHJSONSH from \"../assets/CH,J,SH.png\";\n// import imageFV from \"../assets/FV.png\";\n// import imageL from \"../assets/L.png\";\n// import imageO from \"../assets/O.png\";\n// import imageQW from \"../assets/QW.png\";\n// import imageTH from \"../assets/TH.png\";\n// import imageU from \"../assets/U.png\";\n// import imageE from \"../assets/E.png\";\n// import * as SpeechSDK from \"microsoft-cognitiveservices-speech-sdk\";\n\nexport default {\n  data() {\n    return {\n      textInput: \"Please read this text aloud.\",\n      words: [],\n      characters: [],\n      currentWordIndex: -1,\n      currentLetterIndex: 0,\n      speech: new SpeechSynthesisUtterance()\n    };\n  },\n  computed: {},\n  methods: {\n    // speakWithMicrosoft() {\n    //   const speechConfig = SpeechSDK.SpeechConfig.fromSubscription(\n    //     subscriptionKey,\n    //     \"region=southcentralus\"\n    //   );\n    //   const synthesizer = new SpeechSDK.SpeechSynthesizer(\n    //     speechConfig,\n    //     audioConfig\n    //   );\n    //   synthesizer.visemeReceived = (s, e) => {\n    //     const animation = e.animation;\n    //   };\n    //   const ssml =\n    //     '<speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\"><voice name=\"en-US=AriaNeural\">Hello World!</voice></speak>';\n    //   synthesizer.speak(ssml);\n    // },\n    speak() {\n      this.startGettingLetters();\n      this.words = this.textInput.trim().split(/\\s+/);\n      this.currentWordIndex = 0;\n      this.speech.text = this.textInput;\n      this.speech.rate = 0.5;\n      this.speech.onboundary = this.highlightWord;\n      speechSynthesis.speak(this.speech);\n    },\n    highlightWord(event) {\n      if (event.name === \"word\") {\n        this.currentWordIndex = this.textInput.substring(-1, event.charIndex).trim().split(/\\s+/).length;\n      }\n    },\n    startGettingLetters() {\n      this.characters = this.textInput.trim().split(\"\");\n      this.characters.forEach((char, index) => {\n        setTimeout(() => {\n          console.log(index);\n          this.currentLetterIndex = index;\n        }, 1000);\n      });\n    }\n  }\n};","map":{"version":3,"names":["data","textInput","words","characters","currentWordIndex","currentLetterIndex","speech","SpeechSynthesisUtterance","computed","methods","speak","startGettingLetters","trim","split","text","rate","onboundary","highlightWord","speechSynthesis","event","name","substring","charIndex","length","forEach","char","index","setTimeout","console","log"],"sources":["/Users/lopesti/WebTeam/avatar-narrator-poc/src/components/NarratingAvatar.vue"],"sourcesContent":["<template>\n  <div class=\"w-100 h-100 m-5\">\n    <!-- inputing text and submitting -->\n    <textarea v-model=\"textInput\" rows=\"4\" cols=\"50\"></textarea>\n    <button @click=\"speak\" class=\"btn btn-primary\">Read Text</button>\n\n    <!-- <button @click=\"speakWithMicrosoft\" class=\"btn btn-primary\">\n      Read Text with Microsoft\n    </button> -->\n\n    <!-- Displaying text as it is being read -->\n    <div>\n      <span\n        v-for=\"(word, index) in words\"\n        :key=\"index\"\n        :class=\"{ highlighted: index === currentWordIndex }\"\n      >\n        {{ word }} <span> </span>\n      </span>\n    </div>\n\n    <!-- showing letters as they are being spoken -->\n    <div>\n      <span\n        v-for=\"(char, index) in characters\"\n        :key=\"index\"\n        :class=\"{ 'highlighted-pink': index === currentLetterIndex }\"\n      >\n        {{ char }}\n      </span>\n    </div>\n  </div>\n</template>\n\n<script>\n// import imageAEI from \"../assets/AEI.png\";\n// import imageBMP from \"../assets/BMP.png\";\n// import imageN from \"../assets/Nn.png\";\n// import imageCDGKNRSTXYZ from \"../assets/CDGKNRSTXYZ.png\";\n// import imageCHJSONSH from \"../assets/CH,J,SH.png\";\n// import imageFV from \"../assets/FV.png\";\n// import imageL from \"../assets/L.png\";\n// import imageO from \"../assets/O.png\";\n// import imageQW from \"../assets/QW.png\";\n// import imageTH from \"../assets/TH.png\";\n// import imageU from \"../assets/U.png\";\n// import imageE from \"../assets/E.png\";\n// import * as SpeechSDK from \"microsoft-cognitiveservices-speech-sdk\";\n\nexport default {\n  data() {\n    return {\n      textInput: \"Please read this text aloud.\",\n      words: [],\n      characters: [],\n      currentWordIndex: -1,\n      currentLetterIndex: 0,\n      speech: new SpeechSynthesisUtterance(),\n    };\n  },\n  computed: {},\n  methods: {\n    // speakWithMicrosoft() {\n    //   const speechConfig = SpeechSDK.SpeechConfig.fromSubscription(\n    //     subscriptionKey,\n    //     \"region=southcentralus\"\n    //   );\n    //   const synthesizer = new SpeechSDK.SpeechSynthesizer(\n    //     speechConfig,\n    //     audioConfig\n    //   );\n    //   synthesizer.visemeReceived = (s, e) => {\n    //     const animation = e.animation;\n    //   };\n    //   const ssml =\n    //     '<speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\"><voice name=\"en-US=AriaNeural\">Hello World!</voice></speak>';\n    //   synthesizer.speak(ssml);\n    // },\n    speak() {\n      this.startGettingLetters();\n      this.words = this.textInput.trim().split(/\\s+/);\n\n      this.currentWordIndex = 0;\n\n      this.speech.text = this.textInput;\n      this.speech.rate = 0.5;\n\n      this.speech.onboundary = this.highlightWord;\n      speechSynthesis.speak(this.speech);\n    },\n    highlightWord(event) {\n      if (event.name === \"word\") {\n        this.currentWordIndex = this.textInput\n          .substring(-1, event.charIndex)\n          .trim()\n          .split(/\\s+/).length;\n      }\n    },\n    startGettingLetters() {\n      this.characters = this.textInput.trim().split(\"\");\n      this.characters.forEach((char, index) => {\n        setTimeout(() => {\n          console.log(index);\n          this.currentLetterIndex = index;\n        }, 1000);\n      });\n    },\n  },\n};\n</script>\n\n<style scoped>\n.highlighted {\n  background-color: yellow;\n}\n.highlighted-pink {\n  background-color: pink;\n}\n</style>\n"],"mappings":"AAmCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,eAAe;EACbA,IAAIA,CAAA,EAAG;IACL,OAAO;MACLC,SAAS,EAAE,8BAA8B;MACzCC,KAAK,EAAE,EAAE;MACTC,UAAU,EAAE,EAAE;MACdC,gBAAgB,EAAE,CAAC,CAAC;MACpBC,kBAAkB,EAAE,CAAC;MACrBC,MAAM,EAAE,IAAIC,wBAAwB,CAAC;IACvC,CAAC;EACH,CAAC;EACDC,QAAQ,EAAE,CAAC,CAAC;EACZC,OAAO,EAAE;IACP;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACAC,KAAKA,CAAA,EAAG;MACN,IAAI,CAACC,mBAAmB,CAAC,CAAC;MAC1B,IAAI,CAACT,KAAI,GAAI,IAAI,CAACD,SAAS,CAACW,IAAI,CAAC,CAAC,CAACC,KAAK,CAAC,KAAK,CAAC;MAE/C,IAAI,CAACT,gBAAe,GAAI,CAAC;MAEzB,IAAI,CAACE,MAAM,CAACQ,IAAG,GAAI,IAAI,CAACb,SAAS;MACjC,IAAI,CAACK,MAAM,CAACS,IAAG,GAAI,GAAG;MAEtB,IAAI,CAACT,MAAM,CAACU,UAAS,GAAI,IAAI,CAACC,aAAa;MAC3CC,eAAe,CAACR,KAAK,CAAC,IAAI,CAACJ,MAAM,CAAC;IACpC,CAAC;IACDW,aAAaA,CAACE,KAAK,EAAE;MACnB,IAAIA,KAAK,CAACC,IAAG,KAAM,MAAM,EAAE;QACzB,IAAI,CAAChB,gBAAe,GAAI,IAAI,CAACH,SAAQ,CAClCoB,SAAS,CAAC,CAAC,CAAC,EAAEF,KAAK,CAACG,SAAS,EAC7BV,IAAI,CAAC,EACLC,KAAK,CAAC,KAAK,CAAC,CAACU,MAAM;MACxB;IACF,CAAC;IACDZ,mBAAmBA,CAAA,EAAG;MACpB,IAAI,CAACR,UAAS,GAAI,IAAI,CAACF,SAAS,CAACW,IAAI,CAAC,CAAC,CAACC,KAAK,CAAC,EAAE,CAAC;MACjD,IAAI,CAACV,UAAU,CAACqB,OAAO,CAAC,CAACC,IAAI,EAAEC,KAAK,KAAK;QACvCC,UAAU,CAAC,MAAM;UACfC,OAAO,CAACC,GAAG,CAACH,KAAK,CAAC;UAClB,IAAI,CAACrB,kBAAiB,GAAIqB,KAAK;QACjC,CAAC,EAAE,IAAI,CAAC;MACV,CAAC,CAAC;IACJ;EACF;AACF,CAAC"},"metadata":{},"sourceType":"module","externalDependencies":[]}